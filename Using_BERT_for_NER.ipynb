{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Using BERT for NER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAgpNkGm0JzC",
        "outputId": "92c89a57-d429-4c6f-b330-1ab29204f730"
      },
      "source": [
        "#Imports\r\n",
        "import random\r\n",
        "import os\r\n",
        "random.seed(30) # set random seed for reproducibility\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from itertools import chain\r\n",
        "from collections import Counter\r\n",
        "\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "import sklearn\r\n",
        "import scipy.stats\r\n",
        "from sklearn.metrics import make_scorer\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "# Install java\r\n",
        "! apt-get update -qq\r\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\r\n",
        "\r\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\r\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\r\n",
        "! java -version\r\n",
        "\r\n",
        "# Install pyspark\r\n",
        "! pip install --ignore-installed pyspark==2.4.4\r\n",
        "\r\n",
        "# Install Spark NLP\r\n",
        "! pip install --ignore-installed spark-nlp\r\n",
        "\r\n",
        "#Instal eli5\r\n",
        "! pip install eli5\r\n",
        "\r\n",
        "! pip install sklearn-crfsuite\r\n",
        "\r\n",
        "import eli5\r\n",
        "\r\n",
        "import sklearn_crfsuite\r\n",
        "from sklearn_crfsuite import scorers\r\n",
        "from sklearn_crfsuite import metrics"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "openjdk version \"1.8.0_275\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_275-8u275-b01-0ubuntu1~18.04-b01)\n",
            "OpenJDK 64-Bit Server VM (build 25.275-b01, mixed mode)\n",
            "Processing /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471/pyspark-2.4.4-py2.py3-none-any.whl\n",
            "Collecting py4j==0.10.7\n",
            "  Using cached https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n",
            "Collecting spark-nlp\n",
            "  Using cached https://files.pythonhosted.org/packages/c6/1d/9a2a7c17fc3b3aa78b3921167feed4911d5a055833fea390e7741bba0870/spark_nlp-2.6.5-py2.py3-none-any.whl\n",
            "Installing collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.6.5\n",
            "Collecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.19.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.11.2)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (20.3.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (1.0.0)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.10.1\n",
            "Collecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (4.41.1)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.8.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KZUBJT9LRp_"
      },
      "source": [
        "def parse_data(text, annotation):    \r\n",
        "    # parse annotation-file\r\n",
        "    bio_tag = []\r\n",
        "    with open(annotation, encoding='utf-8') as ann:\r\n",
        "        for l in ann:\r\n",
        "            l = l.split('\\t')\r\n",
        "            tag = l[1].split()[0]\r\n",
        "            if not tag == 'AnnotatorNotes':\r\n",
        "                string = l[2].strip()\r\n",
        "                bio_tag.append((tag, string))\r\n",
        "                \r\n",
        "    # parse text-file and add POS tags\r\n",
        "    sents = []\r\n",
        "    with open(text, encoding='utf-8') as fp:\r\n",
        "        for line in fp:\r\n",
        "            line = line.strip()\r\n",
        "            line = nltk.word_tokenize(line)\r\n",
        "            pos_line = add_pos_tag(line)\r\n",
        "            sents.append(pos_line)\r\n",
        "    \r\n",
        "    # add BIO tags and format data as follows -> (word, pos, biotag)\r\n",
        "    sents = add_bio_tag(sents, bio_tag)\r\n",
        "    \r\n",
        "    return sents\r\n",
        "\r\n",
        "\r\n",
        "def add_pos_tag(sent):\r\n",
        "    return nltk.pos_tag(sent)\r\n",
        "\r\n",
        "\r\n",
        "def add_bio_tag(sents, bio_tag):\r\n",
        "    \"\"\" We use 'cadec/original/' as annotation to add BIO-tags \"\"\"\r\n",
        "    msg = []\r\n",
        "    \r\n",
        "    df= pd.DataFrame()\r\n",
        "    for sent in sents:\r\n",
        "        bio_sent = []\r\n",
        "        remaining = 0\r\n",
        "        for i, word in enumerate(sent):\r\n",
        "            BIOtag = 'O'\r\n",
        "            for j, tag in enumerate(bio_tag):\r\n",
        "                target = nltk.word_tokenize(tag[1])\r\n",
        "                tag = tag[0]\r\n",
        "                count = 0\r\n",
        "                \r\n",
        "                # changes the biotag to either 'B-' or 'I-' when necessary\r\n",
        "                if word[0] == target[0]:\r\n",
        "                    for k in range(len(target)):\r\n",
        "                        if len(sent) > i+k and sent[i+k][0] == target[k]:\r\n",
        "                            count += 1\r\n",
        "                            \r\n",
        "                    # if target is found, the current word gets a 'B-' tag assigned\r\n",
        "                    if count == len(target):\r\n",
        "                        definite_tag = tag\r\n",
        "                        BIOtag = 'B-' + definite_tag\r\n",
        "                        remaining = len(target) - 1\r\n",
        "                        break\r\n",
        "            \r\n",
        "            # changes the biotag to 'I-' when necessary\r\n",
        "            if remaining > 0 and BIOtag == 'O':\r\n",
        "                BIOtag = 'I-' + definite_tag\r\n",
        "                remaining -= 1\r\n",
        "          \r\n",
        "            bio_sent.append((word[0], word[1], BIOtag))\r\n",
        "        msg.append(bio_sent)\r\n",
        "    return msg"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvzrZ4waLG5s"
      },
      "source": [
        "DIR_text = 'cadec/text/'\r\n",
        "DIR_annotation = 'cadec/original/'\r\n",
        "\r\n",
        "data = []\r\n",
        "for f in os.listdir(DIR_text):\r\n",
        "    text = DIR_text + f\r\n",
        "    ann = DIR_annotation + f[:-4] + '.ann'\r\n",
        "    m = parse_data(text, ann)\r\n",
        "    data.append(m)\r\n",
        "\r\n",
        "# shows first patient post\r\n",
        "data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HigKUTTILHDN"
      },
      "source": [
        "#split in test train\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "train, test = train_test_split(data, test_size=0.33, random_state=42)\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "df = pd.DataFrame()\r\n",
        "\r\n",
        "#generate in CONLL format\r\n",
        "f = open(\"data_train2\", \"w\")\r\n",
        "f.write('-DOCSTART- -X- -X- O \\n \\n')\r\n",
        "\r\n",
        "for i in train:\r\n",
        "    for j in i:\r\n",
        "        for k in j:\r\n",
        "            line = k[0] + ' -X- ' + '-X- ' + k[2] + '\\n'\r\n",
        "            f.write(line)\r\n",
        "        f.write('\\n')\r\n",
        "f.close()\r\n",
        "\r\n",
        "g = open('data_test2', 'w')\r\n",
        "g.write('-DOCSTART- -X- -X- O \\n \\n')\r\n",
        "for i in test:\r\n",
        "    for j in i:\r\n",
        "        for k in j:\r\n",
        "            line = k[0] + ' -X- ' + '-X- ' + k[2] + '\\n'\r\n",
        "            g.write(line)\r\n",
        "        g.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvZk__oNLIJB"
      },
      "source": [
        "#Starting BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH1FjJd70Thn",
        "outputId": "6775c7d3-d967-418b-f4c9-294382b3fdd3"
      },
      "source": [
        "from pyspark.sql import SparkSession\r\n",
        "from pyspark.ml import Pipeline\r\n",
        "from sparknlp.annotator import *\r\n",
        "from sparknlp.common import *\r\n",
        "from sparknlp.base import *\r\n",
        "import sparknlp\r\n",
        "\r\n",
        "spark = sparknlp.start()\r\n",
        "print(\"Spark NLP version: \", sparknlp.version())\r\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version:  2.6.5\n",
            "Apache Spark version:  2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzu4QsyA0i2H",
        "outputId": "6c12380b-49af-4334-d0e7-a9e9dfb1d97a"
      },
      "source": [
        "from sparknlp.training import CoNLL\r\n",
        "training_data = CoNLL().readDataset(spark, './data_train2')\r\n",
        "training_data.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Blured vision , c...|[[document, 0, 42...|[[document, 0, 42...|[[token, 0, 5, Bl...|[[pos, 0, 5, -X-,...|[[named_entity, 0...|\n",
            "|        Very shaky ?|[[document, 0, 11...|[[document, 0, 11...|[[token, 0, 3, Ve...|[[pos, 0, 3, -X-,...|[[named_entity, 0...|\n",
            "|After only two we...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 4, Af...|[[pos, 0, 4, -X-,...|[[named_entity, 0...|\n",
            "|Feels like a 'pan...|[[document, 0, 29...|[[document, 0, 29...|[[token, 0, 4, Fe...|[[pos, 0, 4, -X-,...|[[named_entity, 0...|\n",
            "|I would not risk ...|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 0, I,...|[[pos, 0, 0, -X-,...|[[named_entity, 0...|\n",
            "|greatly reduced c...|[[document, 0, 35...|[[document, 0, 35...|[[token, 0, 6, gr...|[[pos, 0, 6, -X-,...|[[named_entity, 0...|\n",
            "|But I 've been ex...|[[document, 0, 80...|[[document, 0, 80...|[[token, 0, 2, Bu...|[[pos, 0, 2, -X-,...|[[named_entity, 0...|\n",
            "|      Some in arms .|[[document, 0, 13...|[[document, 0, 13...|[[token, 0, 3, So...|[[pos, 0, 3, -X-,...|[[named_entity, 0...|\n",
            "|At times pain so ...|[[document, 0, 82...|[[document, 0, 82...|[[token, 0, 1, At...|[[pos, 0, 1, -X-,...|[[named_entity, 0...|\n",
            "|Works for cholest...|[[document, 0, 19...|[[document, 0, 19...|[[token, 0, 4, Wo...|[[pos, 0, 4, -X-,...|[[named_entity, 0...|\n",
            "|muscular pain in ...|[[document, 0, 26...|[[document, 0, 26...|[[token, 0, 7, mu...|[[pos, 0, 7, -X-,...|[[named_entity, 0...|\n",
            "|No side effect fo...|[[document, 0, 13...|[[document, 0, 13...|[[token, 0, 1, No...|[[pos, 0, 1, -X-,...|[[named_entity, 0...|\n",
            "|Worse with exerci...|[[document, 0, 20...|[[document, 0, 20...|[[token, 0, 4, Wo...|[[pos, 0, 4, -X-,...|[[named_entity, 0...|\n",
            "|Legs felt cramped...|[[document, 0, 88...|[[document, 0, 88...|[[token, 0, 3, Le...|[[pos, 0, 3, -X-,...|[[named_entity, 0...|\n",
            "|I had been a regu...|[[document, 0, 71...|[[document, 0, 71...|[[token, 0, 0, I,...|[[pos, 0, 0, -X-,...|[[named_entity, 0...|\n",
            "|My blood work sho...|[[document, 0, 84...|[[document, 0, 84...|[[token, 0, 1, My...|[[pos, 0, 1, -X-,...|[[named_entity, 0...|\n",
            "|The doctor left i...|[[document, 0, 92...|[[document, 0, 92...|[[token, 0, 2, Th...|[[pos, 0, 2, -X-,...|[[named_entity, 0...|\n",
            "|My leg pain seeme...|[[document, 0, 98...|[[document, 0, 98...|[[token, 0, 1, My...|[[pos, 0, 1, -X-,...|[[named_entity, 0...|\n",
            "|I this drug shoul...|[[document, 0, 51...|[[document, 0, 51...|[[token, 0, 0, I,...|[[pos, 0, 0, -X-,...|[[named_entity, 0...|\n",
            "|No side effect no...|[[document, 0, 23...|[[document, 0, 23...|[[token, 0, 1, No...|[[pos, 0, 1, -X-,...|[[named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTM3og9-0nfi",
        "outputId": "f2061053-70b5-4a21-f849-f32afb9ee318"
      },
      "source": [
        "bert = BertEmbeddings.pretrained('bert_base_cased', 'en') \\\r\n",
        " .setInputCols([\"sentence\",'token'])\\\r\n",
        " .setOutputCol(\"bert\")\\\r\n",
        " .setCaseSensitive(False)\r\n",
        "\r\n",
        "nerTagger = NerDLApproach()\\\r\n",
        ".setInputCols([\"sentence\", \"token\", \"bert\"])\\\r\n",
        ".setLabelColumn(\"label\")\\\r\n",
        ".setOutputCol(\"ner\")\\\r\n",
        ".setMaxEpochs(1)\\\r\n",
        ".setRandomSeed(0)\\\r\n",
        ".setVerbose(1)\\\r\n",
        ".setValidationSplit(0.2)\\\r\n",
        ".setEvaluationLogExtended(True)\\\r\n",
        ".setEnableOutputLogs(True)\\\r\n",
        ".setIncludeConfidence(True)\\\r\n",
        ".setTestDataset(\"test_withEmbeds.parquet\")\r\n",
        "\r\n",
        "test_data = CoNLL().readDataset(spark, './data_test2')\r\n",
        "test_data = bert.transform(test_data)\r\n",
        "test_data.write.parquet(\"test_withEmbeds.parquet\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnDWEc4y12dh"
      },
      "source": [
        "ner_pipeline = Pipeline(stages = [bert, nerTagger])\r\n",
        "ner_model = ner_pipeline.fit(training_data)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oD9y5Ia14Xg"
      },
      "source": [
        "ner_model.stages[1].write().save('NER_bert_cadac')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKTls_DQHUmI",
        "outputId": "08c85e88-42be-45ae-ba14-d670148623aa"
      },
      "source": [
        "predictions = ner_model.transform(test_data)\r\n",
        "predictions.show()\r\n",
        "predictions.select('token.result','label.result','ner.result').show(truncate=40)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|                bert|                 ner|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|After 1 1/2 years...|[[document, 0, 83...|[[document, 0, 83...|[[token, 0, 4, Af...|[[pos, 0, 4, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|Have stopped taki...|[[document, 0, 62...|[[document, 0, 62...|[[token, 0, 3, Ha...|[[pos, 0, 3, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|Excellent job of ...|[[document, 0, 43...|[[document, 0, 43...|[[token, 0, 8, Ex...|[[pos, 0, 8, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|cut high cholesto...|[[document, 0, 37...|[[document, 0, 37...|[[token, 0, 2, cu...|[[pos, 0, 2, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|MUSCLE PAIN IN LE...|[[document, 0, 53...|[[document, 0, 53...|[[token, 0, 5, MU...|[[pos, 0, 5, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|I WOULD NOT RECOM...|[[document, 0, 31...|[[document, 0, 31...|[[token, 0, 0, I,...|[[pos, 0, 0, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|                no .|[[document, 0, 3,...|[[document, 0, 3,...|[[token, 0, 1, no...|[[pos, 0, 1, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|I have been on li...|[[document, 0, 63...|[[document, 0, 63...|[[token, 0, 0, I,...|[[pos, 0, 0, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|Iwas changed to 1...|[[document, 0, 65...|[[document, 0, 65...|[[token, 0, 3, Iw...|[[pos, 0, 3, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|I do experience l...|[[document, 0, 42...|[[document, 0, 42...|[[token, 0, 0, I,...|[[pos, 0, 0, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|cramping relieved...|[[document, 0, 33...|[[document, 0, 33...|[[token, 0, 7, cr...|[[pos, 0, 7, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|Aching over my en...|[[document, 0, 13...|[[document, 0, 13...|[[token, 0, 5, Ac...|[[pos, 0, 5, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|Doctors make me f...|[[document, 0, 37...|[[document, 0, 37...|[[token, 0, 6, Do...|[[pos, 0, 6, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|Also had severe d...|[[document, 0, 27...|[[document, 0, 27...|[[token, 0, 3, Al...|[[pos, 0, 3, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|Have taken 2-3 di...|[[document, 0, 33...|[[document, 0, 33...|[[token, 0, 3, Ha...|[[pos, 0, 3, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|Like others who h...|[[document, 0, 75...|[[document, 0, 75...|[[token, 0, 3, Li...|[[pos, 0, 3, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|There is a wonder...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 4, Th...|[[pos, 0, 4, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|Fuzzy , dizzy , l...|[[document, 0, 64...|[[document, 0, 64...|[[token, 0, 4, Fu...|[[pos, 0, 4, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|Low grade headach...|[[document, 0, 32...|[[document, 0, 32...|[[token, 0, 2, Lo...|[[pos, 0, 2, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|     Mild insomnia .|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 3, Mi...|[[pos, 0, 3, -X-,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|                                  result|                                  result|                                  result|\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|[After, 1, 1/2, years, of, taking, 10...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
            "|[Have, stopped, taking, drug, one, we...| [O, O, O, O, O, O, O, O, O, O, O, O, O]| [O, O, O, O, O, O, O, O, O, O, O, O, O]|\n",
            "|[Excellent, job, of, lowering, my, ch...|                [O, O, O, O, O, O, O, O]|                [O, O, O, O, O, O, O, O]|\n",
            "|[cut, high, cholestorel, from, 278, t...|                [O, O, O, O, O, O, O, O]|                [O, O, O, O, O, O, O, O]|\n",
            "|[MUSCLE, PAIN, IN, LEFT, ARM, WEAK, F...|[B-ADR, I-ADR, I-ADR, I-ADR, I-ADR, B...|[B-ADR, I-ADR, I-ADR, I-ADR, I-ADR, I...|\n",
            "| [I, WOULD, NOT, RECOMMENDTHIS, DRUG, .]|                      [O, O, O, O, O, O]|                      [O, O, O, O, O, O]|\n",
            "|                                 [no, .]|                                  [O, O]|                                  [O, O]|\n",
            "|[I, have, been, on, lipitor, for, 10,...|[O, O, O, O, B-Drug, O, O, O, O, O, O...|[O, O, O, O, B-Drug, O, O, O, O, O, O...|\n",
            "|[Iwas, changed, to, 10Mg, and, added,...|[O, O, O, O, O, O, B-Drug, I-Drug, I-...|[O, O, O, O, O, O, B-Drug, O, O, O, O...|\n",
            "|[I, do, experience, leg, weakness, an...|    [O, O, O, B-ADR, I-ADR, O, B-ADR, O]|    [O, O, O, B-ADR, I-ADR, O, B-ADR, O]|\n",
            "|[cramping, relieved, with, Potassium, .]|                [B-ADR, O, O, B-Drug, O]|                         [O, O, O, O, O]|\n",
            "|[Aching, over, my, entire, body, ,, e...|[B-ADR, I-ADR, I-ADR, I-ADR, I-ADR, O...|[B-ADR, I-ADR, I-ADR, I-ADR, I-ADR, O...|\n",
            "|[Doctors, make, me, feel, like, I, am...|             [O, O, O, O, O, O, O, O, O]|             [O, O, O, O, O, O, O, O, O]|\n",
            "|      [Also, had, severe, depression, .]|                 [O, O, B-ADR, I-ADR, O]|                 [O, O, B-ADR, B-ADR, O]|\n",
            "|[Have, taken, 2-3, different, statins...|                      [O, O, O, O, O, O]|                      [O, O, O, O, O, O]|\n",
            "|[Like, others, who, have, written, in...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
            "|[There, is, a, wonderful, website, Sp...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
            "|[Fuzzy, ,, dizzy, ,, light-headedness...|[B-ADR, O, B-ADR, O, B-ADR, I-ADR, O,...|[B-ADR, O, B-ADR, O, B-ADR, I-ADR, O,...|\n",
            "|[Low, grade, headache, goes, with, it...|       [B-ADR, I-ADR, I-ADR, O, O, O, O]|                   [O, O, O, O, O, O, O]|\n",
            "|                     [Mild, insomnia, .]|                       [B-ADR, I-ADR, O]|                       [B-ADR, I-ADR, O]|\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPgiikpCH6Vd",
        "outputId": "5624c233-c511-4fb9-f45c-1f34082402e2"
      },
      "source": [
        "import pyspark.sql.functions as F\r\n",
        "\r\n",
        "predictions.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\r\n",
        ".select(F.expr(\"cols['0']\").alias(\"token\"),\r\n",
        "        F.expr(\"cols['1']\").alias(\"ground_truth\"),\r\n",
        "        F.expr(\"cols['2']\").alias(\"prediction\")).show(truncate=False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+------------+----------+\n",
            "|token       |ground_truth|prediction|\n",
            "+------------+------------+----------+\n",
            "|After       |O           |O         |\n",
            "|1           |O           |O         |\n",
            "|1/2         |O           |O         |\n",
            "|years       |O           |O         |\n",
            "|of          |O           |O         |\n",
            "|taking      |O           |O         |\n",
            "|10          |O           |O         |\n",
            "|mg/         |O           |O         |\n",
            "|day         |O           |O         |\n",
            "|I           |O           |O         |\n",
            "|am          |O           |O         |\n",
            "|experiencing|O           |O         |\n",
            "|constant    |B-ADR       |O         |\n",
            "|gas         |I-ADR       |B-ADR     |\n",
            "|and         |O           |O         |\n",
            "|diarrhea    |B-ADR       |B-ADR     |\n",
            "|.           |O           |O         |\n",
            "|Have        |O           |O         |\n",
            "|stopped     |O           |O         |\n",
            "|taking      |O           |O         |\n",
            "+------------+------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}